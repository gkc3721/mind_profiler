# Profile Summary Filename Mismatch - FIXED ‚úÖ

## Problem

The summary Excel file was being created with the wrong filename, causing the download feature to fail.

### What Was Happening

**Run with ID:** `20251201_014614`

**Expected filename:** `profile_summary20251201_014614.xlsx`  
**Actual filename:** `profile_summary1022.xlsx`

**Log output:**
```
‚úÖ Generating profile summary from log: .../runs/20251201_014614/processing_log20251201_014614.csv
√ñzet Excel kaydedildi: .../runs/20251201_014614/profile_summary1022.xlsx
...
‚ö†Ô∏è Summary file not created at .../runs/20251201_014614/profile_summary20251201_014614.xlsx
‚ö†Ô∏è Profile summary generation failed
```

**Result:** Frontend never got the download link because the backend couldn't find the file.

## Root Cause

The `analyze_processing_log.py` script was trying to extract the run_id from the log filename using this regex:

```python
match = re.search(r'processing_log(\d+)\.csv', log_basename)
```

This regex pattern **only matches digits**, but our run_id format is `20251201_014614` (includes underscore).

When the regex failed to match:
1. It fell back to `_get_last_run_id()` which reads from a counter file
2. The counter file had `1022` in it
3. Summary was saved as `profile_summary1022.xlsx`
4. Code looked for `profile_summary20251201_014614.xlsx`
5. File not found ‚Üí "Summary generation failed"

## Solution

### Fix 1: Update `analyze_processing_log.py`

**Added `run_id_arg` parameter to main function:**

```python
def main(log_arg=None, out_arg=None, run_id_arg=None):
    # ... existing code ...
    
    # Use provided run_id or extract from log filename or use counter file
    run_id = run_id_arg  # ‚Üê NEW: Use provided run_id first
    if run_id is None:
        log_basename = os.path.basename(log_path)
        # Try to match timestamp format like 20251201_014614 or just digits
        match = re.search(r'processing_log([0-9_]+)\.csv', log_basename)  # ‚Üê UPDATED regex
        if match:
            run_id = match.group(1)
        else:
            run_id = _get_last_run_id()
    
    # ... rest of code ...
    out_path = os.path.join(out_dir, f"profile_summary{run_id}.xlsx")
```

**Changes:**
1. Added `run_id_arg=None` parameter
2. Use provided `run_id_arg` first (if given)
3. Updated regex to `r'processing_log([0-9_]+)\.csv'` to match timestamps with underscores
4. Fall back to counter file only if both above methods fail

### Fix 2: Update `engine.py`

**Modified `generate_profile_summary()` to pass run_id:**

```python
def generate_profile_summary(log_path: str, output_dir: str, run_id: str) -> Path | None:
    try:
        from analyze_processing_log import main as analyze_log_main
        
        # Call with run_id_arg to ensure consistent filename
        analyze_log_main(log_path, output_dir, run_id_arg=run_id)  # ‚Üê NEW: Pass run_id
        
        # The file should now be created with the correct name
        expected_path = Path(output_dir) / f"profile_summary{run_id}.xlsx"
        
        if expected_path.exists():
            return expected_path
        else:
            print(f"‚ö†Ô∏è Summary file not created at {expected_path}")
            return None
    except Exception as e:
        print(f"‚ö†Ô∏è Error generating profile summary: {e}")
        import traceback
        traceback.print_exc()
        return None
```

**Changes:**
1. Explicitly pass `run_id_arg=run_id` to `analyze_log_main()`
2. Removed fallback logic that checked for alternative filenames
3. Now expects exactly `profile_summary{run_id}.xlsx`

## How It Works Now

### Flow Diagram

```
User runs pipeline with run_id = "20251201_014614"
  ‚Üì
engine.run_batch() or engine.run_single()
  ‚Üì
Calls generate_profile_summary(log_path, output_dir, run_id="20251201_014614")
  ‚Üì
Calls analyze_log_main(log_path, output_dir, run_id_arg="20251201_014614")
  ‚Üì
analyze_processing_log.py uses run_id_arg = "20251201_014614"
  ‚Üì
Creates file: profile_summary20251201_014614.xlsx
  ‚Üì
engine checks for: profile_summary20251201_014614.xlsx
  ‚Üì
‚úÖ File found!
  ‚Üì
Returns: summary_xlsx="profile_summary20251201_014614.xlsx"
  ‚Üì
Frontend shows "Download Excel" button
  ‚Üì
User clicks ‚Üí Downloads profile_summary_20251201_014614.xlsx
```

## Expected Console Output

After the fix, you should see:

```
‚úÖ Generating profile summary from log: .../runs/20251201_014614/processing_log20251201_014614.csv
Log dosyasƒ±: .../runs/20251201_014614/processing_log20251201_014614.csv
... (analysis output) ...
√ñzet Excel kaydedildi: .../runs/20251201_014614/profile_summary20251201_014614.xlsx
‚úÖ Profile summary created: .../runs/20251201_014614/profile_summary20251201_014614.xlsx

üîç DEBUG - Run completed:
  Run ID: 20251201_014614
  Run dir: .../runs/20251201_014614
  Summary file: .../runs/20251201_014614/profile_summary20251201_014614.xlsx
  Plots dir exists: True
  Plots count: 42
```

**Key indicators:**
- ‚úÖ Same run_id throughout the process
- ‚úÖ "√ñzet Excel kaydedildi" shows correct filename
- ‚úÖ "Profile summary created" confirms success
- ‚úÖ No "‚ö†Ô∏è Summary file not created" warning

## Files Modified

1. ‚úÖ `analyze_processing_log.py` - Added `run_id_arg` parameter, updated regex
2. ‚úÖ `backend/app/core/engine.py` - Pass `run_id` to summary generation

## Testing Steps

### Test 1: Run the Pipeline

1. Backend should auto-reload (check terminal)
2. Open http://localhost:5173
3. Run a pipeline with your sample data
4. Watch backend console

### Test 2: Verify Console Output

Look for this pattern:
```
√ñzet Excel kaydedildi: .../profile_summary{RUN_ID}.xlsx
‚úÖ Profile summary created: .../profile_summary{RUN_ID}.xlsx
```

Where `{RUN_ID}` is the same throughout (e.g., `20251201_014614`).

**Red flags (should NOT see):**
- ‚ùå `profile_summary1022.xlsx` or any number that doesn't match the run_id
- ‚ùå `‚ö†Ô∏è Summary file not created at ...`
- ‚ùå `‚ö†Ô∏è Profile summary generation failed`

### Test 3: Check File System

```bash
# Find the latest run directory
cd backend/app/data/runs
ls -lt | head -n 5

# Check the summary file
cd {latest_run_id}
ls -la profile_summary*.xlsx
```

**Expected:**
```
profile_summary20251201_014614.xlsx  ‚Üê Should match the run_id
```

**Should NOT see:**
```
profile_summary1022.xlsx  ‚Üê Wrong!
```

### Test 4: Verify Frontend

After a successful run:
1. ‚úÖ "Download Excel" button should appear
2. ‚úÖ Clicking it should download the file
3. ‚úÖ Filename should be `profile_summary_{run_id}.xlsx`
4. ‚úÖ File should open in Excel with data

## Backward Compatibility

The fix maintains backward compatibility:

1. **If `run_id_arg` is provided:** Uses it (new behavior)
2. **If `run_id_arg` is None:** Falls back to extracting from filename (old behavior)
3. **Updated regex:** Now matches both:
   - Old format: `processing_log1022.csv` ‚Üí run_id = `1022`
   - New format: `processing_log20251201_014614.csv` ‚Üí run_id = `20251201_014614`

This means:
- ‚úÖ New runs will use timestamp-based run_ids
- ‚úÖ Old runs (if any) will still work with numeric run_ids
- ‚úÖ No breaking changes to existing functionality

## Summary

**Problem:** Filename mismatch due to incorrect run_id extraction  
**Cause:** Regex only matched digits, not timestamp format with underscores  
**Fix:** Pass run_id explicitly + update regex as fallback  
**Result:** Consistent filenames throughout the pipeline  

**Files changed:** 2  
**Lines changed:** ~15  
**Business logic changed:** None (only filename/path handling)

The fix is minimal, focused, and doesn't touch any EEG analysis logic. ‚úÖ
